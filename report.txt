 Project Report: β-VAE Based Anomaly Detection on MNIST

 1. Objective

The objective of this project is to detect anomalies in handwritten digit images using a Variational Autoencoder (VAE). The model is trained only on a single normal class (digit 1) and tested on the full MNIST dataset. Digits other than 1 are treated as anomalies.

 2. Dataset Description

 Dataset: MNIST handwritten digits
 Image size: 28 × 28 grayscale
 Training data: Only digit 1
 Test data: All digits (0–9)
 Normal class: Digit 1
 Anomalies: Digits 0, 2–9

 3. Model Architecture

A fully connected β-VAE is used:

 Encoder: 784 → 400 → latent space (20 dimensions)
 Latent variables: Mean (μ) and Log-Variance (logσ²)
 Decoder: 20 → 400 → 784
 Activation: ReLU (hidden layers), Sigmoid (output layer)

 4. Loss Function

The loss function is the Evidence Lower Bound (ELBO):

 Reconstruction Loss: Binary Cross Entropy (BCE)
 Regularization Term: KL Divergence
 Total Loss = BCE + β × KL Divergence

Two β values were tested:

 β = 1.0 (Standard VAE)
 β = 2.0 (Stronger regularization)

 5. Training Setup

 Optimizer: Adam
 Learning Rate: 0.001
 Batch Size: 128
 Epochs: 10
 Device: CPU / GPU (if available)

 6. Anomaly Detection Method

 Reconstruction error is computed using Mean Squared Error (MSE)
 A threshold is defined at the 99th percentile of reconstruction error
 Samples above the threshold are classified as anomalies

 7. Evaluation Metrics

 Precision
 Recall
 ROC-AUC

8. Final Results

 β Value:1.0
 Precision:1.000
 Recall:0.011
 AUC:0.999

 β Value:2.0
 Precision:1.000
 Recall:0.011
 AUC:0.999
  



 9. Summary

The β-VAE model successfully separates normal and anomalous samples based on reconstruction error. Both β values show excellent discrimination ability as reflected by the high AUC score.
